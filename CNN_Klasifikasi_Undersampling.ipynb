{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815b721c",
   "metadata": {},
   "source": [
    "# CNN Custom untuk Klasifikasi Gambar\n",
    "\n",
    "Notebook ini mencakup langkah-langkah:\n",
    "1. Undersampling\n",
    "2. Preprocessing\n",
    "3. Split Dataset\n",
    "4. Model CNN Custom\n",
    "5. Training dan Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc811c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8aa84",
   "metadata": {},
   "source": [
    "## Set Path dan Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9dd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path ke dataset asli dan target output\n",
    "original_dataset_dir = 'dataset'\n",
    "base_dir = 'processed_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "classes = os.listdir(original_dataset_dir)\n",
    "\n",
    "# Fungsi undersampling dan split\n",
    "def prepare_balanced_dataset(original_dir, target_dir, classes, train_split=0.7, val_split=0.2):\n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "    # Hitung jumlah minimum data\n",
    "    min_count = min([len(os.listdir(os.path.join(original_dir, cls))) for cls in classes])\n",
    "\n",
    "    for cls in classes:\n",
    "        img_list = os.listdir(os.path.join(original_dir, cls))\n",
    "        random.shuffle(img_list)\n",
    "        img_list = img_list[:min_count]\n",
    "\n",
    "        train_count = int(train_split * min_count)\n",
    "        val_count = int(val_split * min_count)\n",
    "\n",
    "        for split, count in zip(['train', 'val', 'test'], [train_count, val_count, min_count - train_count - val_count]):\n",
    "            split_dir = os.path.join(target_dir, split, cls)\n",
    "            os.makedirs(split_dir, exist_ok=True)\n",
    "            for img in img_list[:count]:\n",
    "                src = os.path.join(original_dir, cls, img)\n",
    "                dst = os.path.join(split_dir, img)\n",
    "                shutil.copy(src, dst)\n",
    "            img_list = img_list[count:]\n",
    "\n",
    "prepare_balanced_dataset(original_dataset_dir, base_dir, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8fc681",
   "metadata": {},
   "source": [
    "## Preprocessing dan Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38904950",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aeac52",
   "metadata": {},
   "source": [
    "## Model CNN Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b24a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507bbcf4",
   "metadata": {},
   "source": [
    "## Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "y_true = test_generator.classes\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, target_names=classes))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
